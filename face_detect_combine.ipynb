{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install opencv-python opencv-python-headless face_recognition\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0WAtXjcIOdU4",
        "outputId": "7d4b1f17-ee5b-4341-991c-90945ec37968"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (4.10.0.84)\n",
            "Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.11/dist-packages (4.10.0.84)\n",
            "Collecting face_recognition\n",
            "  Downloading face_recognition-1.3.0-py2.py3-none-any.whl.metadata (21 kB)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.11/dist-packages (from opencv-python) (1.26.4)\n",
            "Collecting face-recognition-models>=0.3.0 (from face_recognition)\n",
            "  Downloading face_recognition_models-0.3.0.tar.gz (100.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m100.1/100.1 MB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: Click>=6.0 in /usr/local/lib/python3.11/dist-packages (from face_recognition) (8.1.8)\n",
            "Requirement already satisfied: dlib>=19.7 in /usr/local/lib/python3.11/dist-packages (from face_recognition) (19.24.2)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from face_recognition) (11.1.0)\n",
            "Downloading face_recognition-1.3.0-py2.py3-none-any.whl (15 kB)\n",
            "Building wheels for collected packages: face-recognition-models\n",
            "  Building wheel for face-recognition-models (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for face-recognition-models: filename=face_recognition_models-0.3.0-py2.py3-none-any.whl size=100566162 sha256=885babb258c6e3a4dcf51ab5e712ddcfaedfa1efafe6e96bdffa421d43f7ba1d\n",
            "  Stored in directory: /root/.cache/pip/wheels/04/52/ec/9355da79c29f160b038a20c784db2803c2f9fa2c8a462c176a\n",
            "Successfully built face-recognition-models\n",
            "Installing collected packages: face-recognition-models, face_recognition\n",
            "Successfully installed face-recognition-models-0.3.0 face_recognition-1.3.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PF07iEXyM9K6",
        "outputId": "d56d1693-8e93-4824-bfa1-f9a38181a5b7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Video processed and saved as 'output_oldman_girlwithdad.mp4'\n"
          ]
        }
      ],
      "source": [
        "import cv2\n",
        "import face_recognition\n",
        "\n",
        "# Load the pre-trained Haar Cascade Classifier for face detection\n",
        "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
        "\n",
        "# Load the target image (the face you want to detect)\n",
        "target_image = cv2.imread('/content/drive/MyDrive/dad.png')\n",
        "gray_target = cv2.cvtColor(target_image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "# Detect the face in the target image\n",
        "target_faces = face_cascade.detectMultiScale(gray_target, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))\n",
        "\n",
        "# Get the target face encoding if a face is found\n",
        "if len(target_faces) > 0:\n",
        "    x, y, w, h = target_faces[0]  # Assuming only one face in the target image\n",
        "    target_face_encoding = face_recognition.face_encodings(target_image, [(y, x + w, y + h, x)])[0]\n",
        "else:\n",
        "    print(\"No face detected in the target image.\")\n",
        "    target_face_encoding = None\n",
        "\n",
        "# Proceed only if a target face encoding is available\n",
        "if target_face_encoding is not None:\n",
        "    # Open the video file\n",
        "    video_path = '/content/drive/MyDrive/merge_video_oldman_girlwithdad.mp4'\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "\n",
        "    # Get video properties for output video\n",
        "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "\n",
        "    # Create VideoWriter object to save the output video\n",
        "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "    out = cv2.VideoWriter('output_oldman_girlwithdad.mp4', fourcc, fps, (width, height))\n",
        "\n",
        "    frame_counter = 0  # Keep track of frame index\n",
        "    while True:\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "\n",
        "        # Convert the frame to grayscale\n",
        "        gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "        # Detect faces in the current frame\n",
        "        faces = face_cascade.detectMultiScale(gray_frame, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))\n",
        "\n",
        "        # Check if any detected faces match the target face\n",
        "        for (x, y, w, h) in faces:\n",
        "            face_encoding = face_recognition.face_encodings(frame, [(y, x + w, y + h, x)])[0]\n",
        "            matches = face_recognition.compare_faces([target_face_encoding], face_encoding, tolerance=0.4)\n",
        "            if True in matches:\n",
        "                cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 0, 255), 2)\n",
        "\n",
        "                # Save the frames where the target face is found\n",
        "                out.write(frame)\n",
        "\n",
        "        frame_counter += 1\n",
        "\n",
        "    # Release resources\n",
        "    cap.release()\n",
        "    out.release()\n",
        "    cv2.destroyAllWindows()\n",
        "    print(\"Video processed and saved as 'output_oldman_girlwithdad.mp4'\")\n",
        "else:\n",
        "    print(\"Target face not found, video processing skipped.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import face_recognition\n",
        "import streamlit as st\n",
        "import tempfile\n",
        "import os\n",
        "import numpy as np\n",
        "from io import BytesIO\n",
        "\n",
        "# Function to process the video\n",
        "def process_video(uploaded_video, uploaded_image):\n",
        "    # Load the target image (the face you want to detect)\n",
        "    target_image = cv2.imdecode(np.frombuffer(uploaded_image.read(), np.uint8), cv2.IMREAD_COLOR)\n",
        "    gray_target = cv2.cvtColor(target_image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Use Dlib's face detector for faster detection\n",
        "    face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
        "    target_faces = face_cascade.detectMultiScale(gray_target, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))\n",
        "\n",
        "    # Get the target face encoding if a face is found\n",
        "    if len(target_faces) > 0:\n",
        "        x, y, w, h = target_faces[0]  # Assuming only one face in the target image\n",
        "        target_face_encoding = face_recognition.face_encodings(target_image, [(y, x + w, y + h, x)])[0]\n",
        "    else:\n",
        "        st.error(\"No face detected in the target image.\")\n",
        "        return None\n",
        "\n",
        "    # Open the video file\n",
        "    video_bytes = uploaded_video.read()\n",
        "    video_path = tempfile.NamedTemporaryFile(delete=False, suffix=\".mp4\")\n",
        "    with open(video_path.name, 'wb') as f:\n",
        "        f.write(video_bytes)\n",
        "\n",
        "    cap = cv2.VideoCapture(video_path.name)\n",
        "\n",
        "    # Get video properties for output video\n",
        "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "\n",
        "    # Create a temporary output video file\n",
        "    output_path = tempfile.NamedTemporaryFile(delete=False, suffix=\".mp4\")\n",
        "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "    out = cv2.VideoWriter(output_path.name, fourcc, fps, (width, height))\n",
        "\n",
        "    # Process every 5th frame to speed up\n",
        "    frame_counter = 0\n",
        "    while True:\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "\n",
        "        if frame_counter % 5 == 0:  # Process every 5th frame to speed up\n",
        "            # Convert the frame to grayscale\n",
        "            gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "            # Detect faces in the current frame\n",
        "            faces = face_cascade.detectMultiScale(gray_frame, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))\n",
        "\n",
        "            # Check if any detected faces match the target face\n",
        "            for (x, y, w, h) in faces:\n",
        "                face_encoding = face_recognition.face_encodings(frame, [(y, x + w, y + h, x)])[0]\n",
        "                matches = face_recognition.compare_faces([target_face_encoding], face_encoding, tolerance=0.4)\n",
        "                if True in matches:\n",
        "                    cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 0, 255), 2)\n",
        "                    # Save the frames where the target face is found\n",
        "                    out.write(frame)\n",
        "\n",
        "        frame_counter += 1\n",
        "\n",
        "    # Release resources\n",
        "    cap.release()\n",
        "    out.release()\n",
        "\n",
        "    # Return the processed video for download\n",
        "    with open(output_path.name, \"rb\") as f:\n",
        "        video_bytes = f.read()\n",
        "\n",
        "    # Clean up temporary files\n",
        "    os.remove(video_path.name)\n",
        "    os.remove(output_path.name)\n",
        "\n",
        "    return video_bytes\n",
        "\n",
        "# Streamlit UI\n",
        "st.title(\"Face Detection in Videos\")\n",
        "st.write(\"Upload a video and an image (face) to detect the face and get the output video.\")\n",
        "\n",
        "# Upload components\n",
        "uploaded_video = st.file_uploader(\"Upload a video\", type=[\"mp4\", \"mov\", \"avi\"])\n",
        "uploaded_image = st.file_uploader(\"Upload an image (face)\", type=[\"jpg\", \"png\", \"jpeg\"])\n",
        "\n",
        "# Button to start processing\n",
        "if st.button(\"Process Video\"):\n",
        "    if uploaded_video and uploaded_image:\n",
        "        # Process the video and image\n",
        "        output_video = process_video(uploaded_video, uploaded_image)\n",
        "\n",
        "        if output_video:\n",
        "            # Provide download link for the processed video\n",
        "            st.success(\"Video processed successfully!\")\n",
        "            st.download_button(\"Download Processed Video\", data=output_video, file_name=\"output_video.mp4\", mime=\"video/mp4\")\n",
        "    else:\n",
        "        st.error(\"Please upload both a video and an image.\")\n"
      ],
      "metadata": {
        "id": "l0HTBCwDTkzg"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}